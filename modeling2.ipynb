{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pickle\n","import sys\n","import time\n","from os.path import abspath, dirname\n","from time import time\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from dlib import get_frontal_face_detector\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","\n","from_generator = tf.data.Dataset.from_generator\n","np.random.seed(666)\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","\n","class DataPrep():\n","\n","    def __init__(self, segment_size=5, rsz=(128, 128)):\n","        self.fd = get_frontal_face_detector()\n","        self.segment_size = segment_size\n","        self.frames = None\n","        self.flows = None\n","        self.rsz = rsz\n","\n","    def getFrameSnippet(self, filepath, start_frame=None):\n","        cap = cv2.VideoCapture(filepath)\n","        frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        if not start_frame:\n","            start_frame = np.random.choice(range(int(frameCount)), size=1)[0]\n","        if frameCount - start_frame < self.segment_size:\n","            start_frame = 0\n","        self.frames = np.empty(\n","            (self.segment_size, frameHeight, frameWidth, 3), dtype=np.uint8)\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n","        j = 0\n","        while j < self.segment_size:\n","            ret, self.frames[j] = cap.read()\n","            j += 1\n","        cap.release()\n","\n","    def getOpticalFlows(self):\n","        if self.frames is not None:\n","            self.flows = np.empty(\n","                (self.frames.shape[0] - 1,\n","                 self.frames.shape[1],\n","                 self.frames.shape[2],\n","                 2))\n","            prvs = cv2.cvtColor(\n","                self.frames[0].astype(np.uint8), cv2.COLOR_BGR2GRAY)\n","            for i in range(1, int(self.frames.shape[0])):\n","                frame = cv2.cvtColor(\n","                    self.frames[i].astype(np.uint8), cv2.COLOR_BGR2GRAY)\n","                self.flows[i - 1] = cv2.calcOpticalFlowFarneback(\n","                    prvs, frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","                prvs = frame\n","\n","    def resize(self, frame):\n","        # TODO: will want to test different sizes here as a hyperparameter\n","        height, width = self.rsz\n","        return cv2.resize(frame, (height, width))\n","\n","    def getFaces(self, frame, grayscale=True):\n","        orig_frame = frame\n","        if grayscale:\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = self.fd(frame, 0)\n","        if len(faces) < 1:\n","            frame = cv2.equalizeHist(frame)\n","            faces = self.fd(frame, 0)\n","        if len(faces) < 1:\n","            faces = orig_frame\n","        return faces\n","\n","    def getFaceRois(self, frame, faces):\n","        if isinstance(faces, np.ndarray):\n","            return self.resize(frame)\n","        f = faces[0]\n","        h = f.bottom() - f.top()\n","        face_rois = None\n","        for face in faces:\n","            x, y, r = f.left(), f.top(), f.right()\n","            w = r - x\n","            roi = frame[y:y + h, x:x + w, :]\n","            if face_rois is None:\n","                face_rois = roi\n","            else:\n","                face_rois = np.hstack((face_rois, roi))\n","        face_rois = self.resize(face_rois)\n","        return face_rois\n","\n","    def prepVid(self, filepath, start_frame=None):\n","        self.getFrameSnippet(filepath, start_frame)\n","        self.getOpticalFlows()\n","        w, h = self.rsz\n","        rgb_rois = np.empty((self.segment_size, w, h, 3), dtype=np.int8)\n","        flow_rois = np.empty(\n","            (self.segment_size - 1, w, h, 2), dtype=np.float32)\n","        for i, frame in enumerate(self.frames):\n","            faces = self.getFaces(frame)\n","            rois = self.getFaceRois(frame, faces)\n","            rgb_rois[i] = rois\n","            if i == 0:\n","                continue\n","            else:\n","                flow = self.flows[i - 1]\n","                rois = self.getFaceRois(flow, faces)\n","                flow_rois[i - 1] = rois\n","        return rgb_rois, flow_rois\n","\n","    def prepFullFrames(self, filepath, start_frame=None):\n","        self.getFrameSnippet(filepath, start_frame)\n","        self.getOpticalFlows()\n","        w, h = self.rsz\n","        rgb_rois = np.empty((self.segment_size, w, h, 3), dtype=np.int8)\n","        flow_rois = np.empty(\n","            (self.segment_size - 1, w, h, 2), dtype=np.float32)\n","        for i, frame in enumerate(self.frames):\n","            rois = self.resize(frame)\n","            rgb_rois[i] = rois\n","            if i == 0:\n","                continue\n","            else:\n","                flow = self.flows[i - 1]\n","                rois = self.resize(flow)\n","                flow_rois[i - 1] = rois\n","        return rgb_rois, flow_rois\n","\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","def input_fn(files, labels, segment_size=5, batch_size=1, rsz=(128, 128)):\n","    def dataGenerator():\n","        for f, label in zip(files, labels):\n","            dp = DataPrep(segment_size=segment_size, rsz=rsz)\n","            frames, flows = dp.prepVid(filepath=f)\n","            yield {'rgb_input': frames, 'flow_input': flows}, label\n","    dataset = from_generator(\n","        dataGenerator,\n","        output_types=(\n","            {\n","                \"rgb_input\": tf.int8,\n","                \"flow_input\": tf.float32\n","            },\n","            tf.int8),\n","        output_shapes=(\n","            {\n","                \"rgb_input\": (segment_size, rsz[0], rsz[1], 3),\n","                \"flow_input\": (segment_size - 1, rsz[0], rsz[1], 2)\n","            },\n","            (2,))\n","    )\n","    dataset = dataset.batch(batch_size)\n","    return dataset\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"FAKE 0.6228373702422145\nREAL 2.535211267605634\n360 360 40 40\n"}],"source":["filepath = 'data/train_sample_videos'\n","segment_size = 5\n","datapath = os.path.join(filepath, 'metadata.json')\n","data = pd.read_json(datapath).T\n","files = [os.path.join(filepath, f) for f in data.index]\n","labels = data.label.values\n","x_train, x_test, y_train, y_test = train_test_split(\n","    files, labels, test_size=0.1)\n","class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n","for k, v in zip(np.unique(y_train), class_weights):\n","    print(k, v)\n","y_train = list(map(lambda x: 0 if x == 'REAL' else 1, y_train))\n","y_test = list(map(lambda x: 0 if x == 'REAL' else 1, y_test))\n","y_train = to_categorical(y_train, num_classes=2)\n","y_test = to_categorical(y_test, num_classes=2)\n","print(len(x_train), len(y_train), len(x_test), len(y_test))\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["batch_size = 4\n","segment_size = 10\n","rsz = (128, 128)\n","train_data = input_fn(\n","    x_train,\n","    y_train,\n","    segment_size=segment_size,\n","    batch_size=batch_size,\n","    rsz=rsz)\n","test_data = input_fn(\n","    x_test,\n","    y_test,\n","    segment_size=segment_size,\n","    batch_size=batch_size,\n","    rsz=rsz)\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["rgb_input = tf.keras.Input(\n","    shape=(segment_size, rsz[0], rsz[1], 3),\n","    name='rgb_input')\n","flow_input = tf.keras.Input(\n","    shape=(segment_size - 1, rsz[0], rsz[1], 2),\n","    name='flow_input')\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nrgb_input (InputLayer)          [(None, 10, 128, 128 0                                            \n__________________________________________________________________________________________________\nconv3d (Conv3D)                 (None, 10, 128, 128, 656         rgb_input[0][0]                  \n__________________________________________________________________________________________________\nconv3d_1 (Conv3D)               (None, 10, 128, 128, 4104        conv3d[0][0]                     \n__________________________________________________________________________________________________\nmax_pooling3d (MaxPooling3D)    (None, 5, 64, 64, 8) 0           conv3d_1[0][0]                   \n__________________________________________________________________________________________________\nconv3d_2 (Conv3D)               (None, 5, 64, 64, 8) 1736        max_pooling3d[0][0]              \n__________________________________________________________________________________________________\nconv3d_3 (Conv3D)               (None, 5, 64, 64, 8) 4104        conv3d_2[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 5, 64, 64, 8) 0           conv3d_3[0][0]                   \n                                                                 max_pooling3d[0][0]              \n__________________________________________________________________________________________________\nconv3d_4 (Conv3D)               (None, 5, 64, 64, 8) 1736        add[0][0]                        \n__________________________________________________________________________________________________\nconv3d_5 (Conv3D)               (None, 5, 64, 64, 8) 4104        conv3d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 5, 64, 64, 8) 0           conv3d_5[0][0]                   \n                                                                 add[0][0]                        \n__________________________________________________________________________________________________\nconv3d_6 (Conv3D)               (None, 5, 64, 64, 8) 1736        add_1[0][0]                      \n__________________________________________________________________________________________________\nglobal_average_pooling3d (Globa (None, 8)            0           conv3d_6[0][0]                   \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           576         global_average_pooling3d[0][0]   \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 64)           0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2)            130         dropout[0][0]                    \n==================================================================================================\nTotal params: 18,882\nTrainable params: 18,882\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"}],"source":["# block 1\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(rgb_input)\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=4,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(x)\n","block1_output = layers.MaxPool3D(\n","    pool_size=(2, 2, 2),\n","    strides=(2, 2, 2),\n","    padding='same'\n",")(x)\n","# block 2\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(block1_output)\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=4,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(x)\n","block2_output = layers.add([x, block1_output])\n","# block 3\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(block2_output)\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=4,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(x)\n","block3_output = layers.add([x, block2_output])\n","\n","x = layers.Conv3D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=(1, 1, 1),\n","    padding='same',\n","    data_format='channels_last',\n","    activation='relu',\n",")(block3_output)\n","x = layers.GlobalAveragePooling3D()(x)\n","x = layers.Dense(64, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","rgb_outputs = layers.Dense(2, activation='softmax')(x)\n","\n","rgb_model = Model(inputs=rgb_input, outputs=rgb_outputs)\n","rgb_model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflow_input (InputLayer)      [(None, 9, 128, 128, 2)]  0         \n_________________________________________________________________\nconv_lst_m2d (ConvLSTM2D)    (None, 9, 128, 128, 8)    2912      \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 9, 128, 128, 8)    32        \n_________________________________________________________________\nconv_lst_m2d_1 (ConvLSTM2D)  (None, 9, 128, 128, 8)    4640      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 9, 128, 128, 8)    32        \n_________________________________________________________________\nconv_lst_m2d_2 (ConvLSTM2D)  (None, 128, 128, 8)       4640      \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 128, 128, 8)       32        \n_________________________________________________________________\nflatten (Flatten)            (None, 131072)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16777344  \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 16,822,914\nTrainable params: 16,822,866\nNon-trainable params: 48\n_________________________________________________________________\n"}],"source":["x = layers.ConvLSTM2D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=1,\n","    padding='same',\n","    data_format='channels_last',\n","    return_sequences=True,\n","    dropout=0.5\n",")(flow_input)\n","x = layers.BatchNormalization()(x)\n","x = layers.ConvLSTM2D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=1,\n","    padding='same',\n","    data_format='channels_last',\n","    return_sequences=True,\n","    dropout=0.5\n",")(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.ConvLSTM2D(\n","    filters=8,\n","    kernel_size=3,\n","    strides=1,\n","    padding='same',\n","    data_format='channels_last',\n","    return_sequences=False,\n","    dropout=0.5\n",")(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","flow_output = layers.Dense(2)(x)\n","flow_model = Model(inputs=flow_input, outputs=flow_output)\n","flow_model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"my_model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nrgb_input (InputLayer)          [(None, 10, 128, 128 0                                            \n__________________________________________________________________________________________________\nconv3d (Conv3D)                 (None, 10, 128, 128, 656         rgb_input[0][0]                  \n__________________________________________________________________________________________________\nconv3d_1 (Conv3D)               (None, 10, 128, 128, 4104        conv3d[0][0]                     \n__________________________________________________________________________________________________\nflow_input (InputLayer)         [(None, 9, 128, 128, 0                                            \n__________________________________________________________________________________________________\nmax_pooling3d (MaxPooling3D)    (None, 5, 64, 64, 8) 0           conv3d_1[0][0]                   \n__________________________________________________________________________________________________\nconv_lst_m2d (ConvLSTM2D)       (None, 9, 128, 128,  2912        flow_input[0][0]                 \n__________________________________________________________________________________________________\nconv3d_2 (Conv3D)               (None, 5, 64, 64, 8) 1736        max_pooling3d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 9, 128, 128,  32          conv_lst_m2d[0][0]               \n__________________________________________________________________________________________________\nconv3d_3 (Conv3D)               (None, 5, 64, 64, 8) 4104        conv3d_2[0][0]                   \n__________________________________________________________________________________________________\nconv_lst_m2d_1 (ConvLSTM2D)     (None, 9, 128, 128,  4640        batch_normalization[0][0]        \n__________________________________________________________________________________________________\nadd (Add)                       (None, 5, 64, 64, 8) 0           conv3d_3[0][0]                   \n                                                                 max_pooling3d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 9, 128, 128,  32          conv_lst_m2d_1[0][0]             \n__________________________________________________________________________________________________\nconv3d_4 (Conv3D)               (None, 5, 64, 64, 8) 1736        add[0][0]                        \n__________________________________________________________________________________________________\nconv_lst_m2d_2 (ConvLSTM2D)     (None, 128, 128, 8)  4640        batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv3d_5 (Conv3D)               (None, 5, 64, 64, 8) 4104        conv3d_4[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 128, 128, 8)  32          conv_lst_m2d_2[0][0]             \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 5, 64, 64, 8) 0           conv3d_5[0][0]                   \n                                                                 add[0][0]                        \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 131072)       0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv3d_6 (Conv3D)               (None, 5, 64, 64, 8) 1736        add_1[0][0]                      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 128)          16777344    flatten[0][0]                    \n__________________________________________________________________________________________________\nglobal_average_pooling3d (Globa (None, 8)            0           conv3d_6[0][0]                   \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 128)          16512       dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 64)           576         global_average_pooling3d[0][0]   \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 128)          16512       dense_3[0][0]                    \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 64)           0           dense[0][0]                      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2)            130         dropout[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n__________________________________________________________________________________________________\naverage (Average)               (None, 2)            0           dense_1[0][0]                    \n                                                                 dense_5[0][0]                    \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 2)            0           average[0][0]                    \n__________________________________________________________________________________________________\nfinal_output (Dense)            (None, 2)            6           flatten_1[0][0]                  \n==================================================================================================\nTotal params: 16,841,802\nTrainable params: 16,841,754\nNon-trainable params: 48\n__________________________________________________________________________________________________\n"}],"source":["final_average = layers.average([rgb_outputs, flow_output])\n","x = layers.Flatten()(final_average)\n","final_output = layers.Dense(2, activation='softmax', name='final_output')(x)\n","model = Model(\n","    inputs={\"rgb_input\": rgb_input, \"flow_input\": flow_input},\n","    outputs=final_output,\n","    name='my_model'\n",")\n","model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"}],"source":["tf.keras.utils.plot_model(\n","    model,\n","    to_file='model.png',\n","    show_shapes=True,\n","    show_layer_names=True\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/5\n90/90 [==============================] - 3157s 35s/step - loss: 0.9900 - acc: 0.6944 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\nEpoch 2/5\n 9/10 [==========================>...] - ETA: 31s - loss: 0.5973 - acc: 0.7778"}],"source":["opt = tf.keras.optimizers.Adam()\n","model.compile(\n","    optimizer=opt,\n","    loss='categorical_crossentropy',\n","    metrics=['acc'])\n","model.fit(\n","    x=train_data,\n","    validation_data=test_data,\n","    epochs=5,\n","    verbose=1,\n","    class_weight=class_weights\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.evaluate(\n","    test_data\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"}}}