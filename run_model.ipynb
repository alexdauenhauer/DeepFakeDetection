{"cells":[{"source":["import os\n","import pickle\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import (BatchNormalization, ConvLSTM2D, Dense,\n","                                     Input, LeakyReLU, Conv3D)\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","from_generator = tf.data.Dataset.from_generator\n","\n","from DataPrep import DataPrep\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","# TODO: add variables for frame height and width\n","# def input_fn(filepath, batch_size=10, segment_size=5):\n","\n","filepath = 'data/train_sample_videos'\n","segment_size = 5\n","datapath = os.path.join(filepath, 'metadata.json')\n","data = pd.read_json(os.path.join(datapath)).T\n","files = [os.path.join(filepath, f) for f in data.index]\n","labels = data.label.values\n","x_train, x_test, y_train, y_test = train_test_split(\n","    files, labels, test_size=0.2)\n","class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n","for k, v in zip(np.unique(y_train), class_weights):\n","    print(k, v)\n","y_train = list(map(lambda x: 0 if x == 'REAL' else 1, y_train))\n","y_test = list(map(lambda x: 0 if x == 'REAL' else 1, y_test))\n","y_train = to_categorical(y_train, num_classes=2)\n","y_test = to_categorical(y_test, num_classes=2)\n","print(len(x_train), len(y_train), len(x_test), len(y_test))\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","# @tf.function\n","def input_fn(files, labels, segment_size=5, batch_size=1):\n","    def dataGenerator():\n","        for f, label in zip(files, labels):\n","            dp = DataPrep(segment_size=segment_size)\n","            frames = dp.prepFullFrames(filepath=f)\n","            flows = dp.getOpticalFlows()\n","            yield {'rgb_input': frames, 'flow_input': flows}, label\n","    dataset = from_generator(\n","        dataGenerator,\n","        output_types=(\n","            {\n","                \"rgb_input\": tf.int8,\n","                \"flow_input\": tf.float32\n","            },\n","            tf.int8),\n","        output_shapes=(\n","            {\n","                \"rgb_input\": (segment_size, 256, 256, 3),\n","                \"flow_input\": (segment_size - 1, 256, 256, 2)\n","            },\n","            (2,))\n","    )\n","    dataset = dataset.batch(batch_size)\n","    return dataset\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["batch_size = 10\n","train_data = input_fn(x_train, y_train, batch_size=batch_size)\n","test_data = input_fn(x_test, y_test, batch_size=batch_size)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["class InputStream(tf.keras.Model):\n","    def __init__(self, kernel_size, filters, name):\n","        super().__init__(name=name)\n","        self.convLstm1 = ConvLSTM2D(\n","            filters=filters,\n","            kernel_size=kernel_size,\n","            strides=1,\n","            padding='same',\n","            data_format='channels_last',\n","            return_sequences=True,\n","            dropout=0.5\n","        )\n","        self.convLstm2 = ConvLSTM2D(\n","            filters=filters,\n","            kernel_size=kernel_size,\n","            strides=1,\n","            padding='same',\n","            data_format='channels_last',\n","            return_sequences=False,\n","            dropout=0.5\n","        )\n","        self.bn = BatchNormalization()\n","        self.act = LeakyReLU()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.dense = Dense(512)\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.out_layer = Dense(2)\n","\n","    # TODO: specify different behavior for training, i.e. dropout only when\n","    # training\n","    def call(self, input_tensor, training=False):\n","        x = self.convLstm1(input_tensor)\n","        x = self.bn(x)\n","        x = self.convLstm1(x)\n","        x = self.bn(x)\n","        x = self.convLstm2(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        x = self.flatten(x)\n","        x = self.dense(x)\n","        x = self.act(x)\n","        x = self.dense(x)\n","        x = self.act(x)\n","        x = self.dense(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        return self.out_layer(x)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# class InputStream(tf.keras.Model):\n","#     def __init__(self, kernel_size, filters, name):\n","#         super().__init__(name=name)\n","\n","# kernel_size = 3\n","# filters = 1\n","# rgb_input = tf.keras.Input(shape=(5, 256, 256, 3), name='rgb_input')\n","# convLstm1 = ConvLSTM2D(\n","#     filters=filters,\n","#     kernel_size=kernel_size,\n","#     strides=1,\n","#     padding='same',\n","#     data_format='channels_last',\n","#     return_sequences=True,\n","#     dropout=0.5\n","# )(rgb_input)\n","# bn = BatchNormalization()(convLstm1)\n","# convLstm2 = ConvLSTM2D(\n","#     filters=filters,\n","#     kernel_size=kernel_size,\n","#     strides=1,\n","#     padding='same',\n","#     data_format='channels_last',\n","#     return_sequences=False,\n","#     dropout=0.5\n","# )(bn)\n","# bn = BatchNormalization()(convLstm2)\n","# flatten = tf.keras.layers.Flatten()(bn)\n","# dense = Dense(512)(flatten)\n","# act = LeakyReLU()(dense)\n","# dense = Dense(512)(act)\n","# act = LeakyReLU()(dense)\n","# dense = Dense(512)(act)\n","# act = LeakyReLU()(dense)\n","# dropout = tf.keras.layers.Dropout(0.5)(act)\n","# out_layer = Dense(2)(dropout)\n","# model = Model(inputs=rgb_input, outputs=out_layer)\n","# model.summary()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["rgb_stream = InputStream(3, 32, 'rgb_stream')\n","flow_stream = InputStream(3, 32, 'flow_stream')\n","rgb_input = tf.keras.Input(shape=(5, 256, 256, 3), name='rgb_input')\n","flow_input = tf.keras.Input(shape=(4, 256, 256, 2), name='flow_input')\n","rgb = rgb_stream(rgb_input)\n","flow = flow_stream(flow_input)\n","final_average = tf.keras.layers.average([rgb, flow])\n","x = tf.keras.layers.Flatten()(final_average)\n","final_output = Dense(2, activation='softmax', name='final_output')(x)\n","model = Model(\n","    inputs={\"rgb_input\": rgb_input, \"flow_input\": flow_input},\n","    outputs=final_output,\n","    name='my_model'\n",")\n","model.summary()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["tf.keras.utils.plot_model(\n","    model,\n","    to_file='model.png',\n","    show_shapes=True,\n","    show_layer_names=True,\n",")\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["opt = tf.keras.optimizers.Adam()\n","model.compile(\n","    optimizer=opt,\n","    loss='categorical_crossentropy',\n","    metrics=['acc'])\n","model.fit(\n","    train_data,\n","    epochs=25,\n","    verbose=1,\n","    class_weight=class_weights\n",")\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["model.evaluate(\n","    test_data,\n","    #     class_weight=class_weights\n",")\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# DEBUGGING\n","dataset = input_fn(filepath, batch_size=1)\n","start = time.time()\n","for i, x in enumerate(dataset):\n","    print(i)\n","    data_dict, label = x\n","    for k, v in data_dict.items():\n","        print(k, v.numpy().shape)\n","    print(time.time() - start)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["filepath = 'data/train_sample_videos'\n","segment_size = 5\n","datapath = os.path.join(filepath, 'metadata.json')\n","data = pd.read_json(os.path.join(datapath)).T\n","files = [os.path.join(filepath, f) for f in data.index]\n","labels = data.label.apply(lambda x: 0 if x == 'REAL' else 1)\n","labels = to_categorical(labels, num_classes=2)\n","for i, (f, label) in enumerate(zip(files, labels)):\n","    try:\n","        dp = DataPrep(segment_size=segment_size)\n","        frames = dp.prepFullFrames(filepath=f)\n","        flows = dp.getOpticalFlows()\n","    except Exception as e:\n","        print(i, f, label)\n","        print(e)\n","        break\n","print('everything is working now')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["f = 'data/train_sample_videos/adhsbajydo.mp4'\n","dp = DataPrep(segment_size=segment_size)\n","frames = dp.prepFullFrames(filepath=f)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}