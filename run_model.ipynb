{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (BatchNormalization, ConvLSTM2D, Dense,\n",
    "                                     Input, LeakyReLU, Conv3D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from_generator = tf.data.Dataset.from_generator\n",
    "\n",
    "from DataPrep import DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE 0.6153846153846154\n",
      "REAL 2.6666666666666665\n",
      "320 320 80 80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: add variables for frame height and width\n",
    "# def input_fn(filepath, batch_size=10, segment_size=5):\n",
    "\n",
    "filepath = 'data/train_sample_videos'\n",
    "segment_size = 5\n",
    "datapath = os.path.join(filepath, 'metadata.json')\n",
    "data = pd.read_json(os.path.join(datapath)).T\n",
    "files = [os.path.join(filepath, f) for f in data.index]\n",
    "labels = data.label.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    files, labels, test_size=0.2)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "for k, v in zip(np.unique(y_train), class_weights):\n",
    "    print(k, v)\n",
    "y_train = list(map(lambda x: 0 if x == 'REAL' else 1, y_train))\n",
    "y_test = list(map(lambda x: 0 if x == 'REAL' else 1, y_test))\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "print(len(x_train), len(y_train), len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @tf.function\n",
    "def input_fn(files, labels, segment_size=5, batch_size=1):\n",
    "    def dataGenerator():\n",
    "        for f, label in zip(files, labels):\n",
    "            dp = DataPrep(segment_size=segment_size)\n",
    "            frames = dp.prepFullFrames(filepath=f)\n",
    "            flows = dp.getOpticalFlows()\n",
    "            yield {'rgb_input': frames, 'flow_input': flows}, label\n",
    "    dataset = from_generator(\n",
    "        dataGenerator,\n",
    "        output_types=(\n",
    "            {\n",
    "                \"rgb_input\": tf.int8,\n",
    "                \"flow_input\": tf.float32\n",
    "            },\n",
    "            tf.int8),\n",
    "        output_shapes=(\n",
    "            {\n",
    "                \"rgb_input\": (segment_size, 256, 256, 3),\n",
    "                \"flow_input\": (segment_size - 1, 256, 256, 2)\n",
    "            },\n",
    "            (2,))\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_data = input_fn(x_train, y_train, batch_size=batch_size)\n",
    "test_data = input_fn(x_test, y_test, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStream(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters, name):\n",
    "        super().__init__(name=name)\n",
    "        self.convLstm1 = ConvLSTM2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            return_sequences=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.convLstm2 = ConvLSTM2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            return_sequences=False,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.bn = BatchNormalization()\n",
    "        self.act = LeakyReLU()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = Dense(512)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.out_layer = Dense(2)\n",
    "\n",
    "    # TODO: specify different behavior for training, i.e. dropout only when\n",
    "    # training\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.convLstm1(input_tensor)\n",
    "        x = self.bn(x)\n",
    "        x = self.convLstm1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.convLstm2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.out_layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-11-1ac709aa669d>:34 call  *\n        x = self.convLstm1(x)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py:299 __call__\n        return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py:623 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py:224 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer conv_lst_m2d_2: expected shape=(None, None, 256, 256, 3), found shape=[None, 5, 256, 256, 32]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0c32cf5ea4ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrgb_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflow_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flow_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfinal_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-11-1ac709aa669d>:34 call  *\n        x = self.convLstm1(x)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py:299 __call__\n        return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py:623 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /root/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py:224 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer conv_lst_m2d_2: expected shape=(None, None, 256, 256, 3), found shape=[None, 5, 256, 256, 32]\n"
     ]
    }
   ],
   "source": [
    "rgb_stream = InputStream(3, 32, 'rgb_stream')\n",
    "flow_stream = InputStream(3, 32, 'flow_stream')\n",
    "rgb_input = tf.keras.Input(shape=(5, 256, 256, 3), name='rgb_input')\n",
    "flow_input = tf.keras.Input(shape=(4, 256, 256, 2), name='flow_input')\n",
    "rgb = rgb_stream(rgb_input)\n",
    "flow = flow_stream(flow_input)\n",
    "final_average = tf.keras.layers.average([rgb, flow])\n",
    "x = tf.keras.layers.Flatten()(final_average)\n",
    "final_output = Dense(2, activation='softmax', name='final_output')(x)\n",
    "model = Model(\n",
    "    inputs={ \"rgb_input\": rgb_input, \"flow_input\": flow_input},\n",
    "    outputs=final_output,\n",
    "    name='my_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=25,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    test_data,\n",
    "#     class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING\n",
    "dataset = input_fn(filepath, batch_size=1)\n",
    "start = time.time()\n",
    "for i, x in enumerate(dataset):\n",
    "    print(i)\n",
    "    data_dict, label = x\n",
    "    for k, v in data_dict.items():\n",
    "        print(k, v.numpy().shape)\n",
    "    print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/train_sample_videos'\n",
    "segment_size = 5\n",
    "datapath = os.path.join(filepath, 'metadata.json')\n",
    "data = pd.read_json(os.path.join(datapath)).T\n",
    "files = [os.path.join(filepath, f) for f in data.index]\n",
    "labels = data.label.apply(lambda x: 0 if x == 'REAL' else 1)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "for i, (f, label) in enumerate(zip(files, labels)):\n",
    "    try:\n",
    "        dp = DataPrep(segment_size=segment_size)\n",
    "        frames = dp.prepFullFrames(filepath=f)\n",
    "        flows = dp.getOpticalFlows()\n",
    "    except Exception as e:\n",
    "        print(i, f, label)\n",
    "        print(e)\n",
    "        break\n",
    "print('everything is working now')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'data/train_sample_videos/adhsbajydo.mp4'\n",
    "dp = DataPrep(segment_size=segment_size)\n",
    "frames = dp.prepFullFrames(filepath=f)\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
