{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (BatchNormalization, ConvLSTM2D, Dense,\n",
    "                                     Input, LeakyReLU, Conv3D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from_generator = tf.data.Dataset.from_generator\n",
    "\n",
    "from DataPrep import DataPrepDlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dlib\n",
    "dlib.DLIB_USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE 0.6274509803921569\n",
      "REAL 2.4615384615384617\n",
      "320 320 80 80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: add variables for frame height and width\n",
    "# def input_fn(filepath, batch_size=10, segment_size=5):\n",
    "\n",
    "filepath = 'data/train_sample_videos'\n",
    "segment_size = 5\n",
    "datapath = os.path.join(filepath, 'metadata.json')\n",
    "data = pd.read_json(datapath).T\n",
    "files = [os.path.join(filepath, f) for f in data.index]\n",
    "labels = data.label.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    files, labels, test_size=0.2)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "for k, v in zip(np.unique(y_train), class_weights):\n",
    "    print(k, v)\n",
    "# y_train = list(map(lambda x: 0 if x == 'REAL' else 1, y_train))\n",
    "# y_test = list(map(lambda x: 0 if x == 'REAL' else 1, y_test))\n",
    "# y_train = to_categorical(y_train, num_classes=2)\n",
    "# y_test = to_categorical(y_test, num_classes=2)\n",
    "y_train = np.array(list(map(lambda x: 0 if x == 'REAL' else 1, y_train)))\n",
    "y_test = np.array(list(map(lambda x: 0 if x == 'REAL' else 1, y_test)))\n",
    "print(len(x_train), len(y_train), len(x_test), len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @tf.function\n",
    "def input_fn(files, labels, segment_size=5, batch_size=1, rsz=(128, 128)):\n",
    "    def dataGenerator():\n",
    "        for f, label in zip(files, labels):\n",
    "            dp = DataPrepDlib(segment_size=segment_size)\n",
    "            frames, flows = dp.prepVid(filepath=f)\n",
    "            yield {'rgb_input': frames, 'flow_input': flows}, label\n",
    "    dataset = from_generator(\n",
    "        dataGenerator,\n",
    "        output_types=(\n",
    "            {\n",
    "                \"rgb_input\": tf.int8,\n",
    "                \"flow_input\": tf.float32\n",
    "            },\n",
    "            tf.int8),\n",
    "        output_shapes=(\n",
    "            {\n",
    "                \"rgb_input\": (segment_size, rsz[0], rsz[1], 3),\n",
    "                \"flow_input\": (segment_size - 1, rsz[0], rsz[1], 2)\n",
    "            },\n",
    "            (2,))\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "rsz = (128, 128)\n",
    "train_data = input_fn(x_train, y_train, batch_size=batch_size, rsz=rsz)\n",
    "test_data = input_fn(x_test, y_test, batch_size=batch_size, rsz=rsz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStream(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters, name):\n",
    "        super().__init__(name=name)\n",
    "        self.convLstm1 = ConvLSTM2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            return_sequences=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.convLstm2 = ConvLSTM2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            return_sequences=True,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.convLstm3 = ConvLSTM2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            return_sequences=False,\n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.act = LeakyReLU()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = Dense(128)\n",
    "        self.act1 = LeakyReLU()\n",
    "        self.dense2 = Dense(128)\n",
    "        self.act2 = LeakyReLU()\n",
    "        self.dense3 = Dense(128)\n",
    "        self.act3 = LeakyReLU()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.out_layer = Dense(2)\n",
    "\n",
    "    # TODO: specify different behavior for training, i.e. dropout only when\n",
    "    # training\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.convLstm1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.convLstm2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.convLstm3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.act3(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.out_layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class InputStream(tf.keras.Model):\n",
    "#     def __init__(self, kernel_size, filters, name):\n",
    "#         super().__init__(name=name)\n",
    "\n",
    "# kernel_size = 3\n",
    "# filters = 1\n",
    "# rgb_input = tf.keras.Input(shape=(5, 256, 256, 3), name='rgb_input')\n",
    "# convLstm1 = ConvLSTM2D(\n",
    "#     filters=filters,\n",
    "#     kernel_size=kernel_size,\n",
    "#     strides=1,\n",
    "#     padding='same',\n",
    "#     data_format='channels_last',\n",
    "#     return_sequences=True,\n",
    "#     dropout=0.5\n",
    "# )(rgb_input)\n",
    "# bn = BatchNormalization()(convLstm1)\n",
    "# convLstm2 = ConvLSTM2D(\n",
    "#     filters=filters,\n",
    "#     kernel_size=kernel_size,\n",
    "#     strides=1,\n",
    "#     padding='same',\n",
    "#     data_format='channels_last',\n",
    "#     return_sequences=False,\n",
    "#     dropout=0.5\n",
    "# )(bn)\n",
    "# bn = BatchNormalization()(convLstm2)\n",
    "# flatten = tf.keras.layers.Flatten()(bn)\n",
    "# dense = Dense(512)(flatten)\n",
    "# act = LeakyReLU()(dense)\n",
    "# dense = Dense(512)(act)\n",
    "# act = LeakyReLU()(dense)\n",
    "# dense = Dense(512)(act)\n",
    "# act = LeakyReLU()(dense)\n",
    "# dropout = tf.keras.layers.Dropout(0.5)(act)\n",
    "# out_layer = Dense(2)(dropout)\n",
    "# model = Model(inputs=rgb_input, outputs=out_layer)\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rgb_input (InputLayer)          [(None, 5, 128, 128, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flow_input (InputLayer)         [(None, 4, 128, 128, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rgb_stream (InputStream)        (None, 2)            8425426     rgb_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flow_stream (InputStream)       (None, 2)            8425282     flow_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 2)            0           rgb_stream[0][0]                 \n",
      "                                                                 flow_stream[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           average[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 2)            6           flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,850,714\n",
      "Trainable params: 16,850,666\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_stream = InputStream(3, 4, 'rgb_stream')\n",
    "flow_stream = InputStream(3, 4, 'flow_stream')\n",
    "rgb_input = tf.keras.Input(shape=(5, rsz[0], rsz[1], 3), name='rgb_input')\n",
    "flow_input = tf.keras.Input(shape=(4, rsz[0], rsz[1], 2), name='flow_input')\n",
    "rgb = rgb_stream(rgb_input)\n",
    "flow = flow_stream(flow_input)\n",
    "final_average = tf.keras.layers.average([rgb, flow])\n",
    "x = tf.keras.layers.Flatten()(final_average)\n",
    "# final_output = Dense(2, activation='softmax', name='final_output')(x)\n",
    "final_output = Dense(1, activation='sigmoid', name='final_output')(x)\n",
    "model = Model(\n",
    "    inputs={\"rgb_input\": rgb_input, \"flow_input\": flow_input},\n",
    "    outputs=final_output,\n",
    "    name='my_model'\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "32/32 [==============================] - 1362s 43s/step - loss: 4.3392 - acc: 0.6625\n",
      "Epoch 2/25\n",
      "32/32 [==============================] - 1345s 42s/step - loss: 2.0393 - acc: 0.6812\n",
      "Epoch 3/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 1.4665 - acc: 0.7000\n",
      "Epoch 4/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 1.2291 - acc: 0.6812\n",
      "Epoch 5/25\n",
      "32/32 [==============================] - 1348s 42s/step - loss: 1.0241 - acc: 0.6719\n",
      "Epoch 6/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.7949 - acc: 0.7094\n",
      "Epoch 7/25\n",
      "32/32 [==============================] - 1358s 42s/step - loss: 0.7622 - acc: 0.7094\n",
      "Epoch 8/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.6581 - acc: 0.7500\n",
      "Epoch 9/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.7004 - acc: 0.7406\n",
      "Epoch 10/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 0.6383 - acc: 0.7312\n",
      "Epoch 11/25\n",
      "32/32 [==============================] - 1353s 42s/step - loss: 0.6408 - acc: 0.7344\n",
      "Epoch 12/25\n",
      "32/32 [==============================] - 1336s 42s/step - loss: 0.6847 - acc: 0.7344\n",
      "Epoch 13/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.6471 - acc: 0.7219\n",
      "Epoch 14/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.6270 - acc: 0.7469\n",
      "Epoch 15/25\n",
      "32/32 [==============================] - 1333s 42s/step - loss: 0.6136 - acc: 0.7625\n",
      "Epoch 16/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.5680 - acc: 0.7781\n",
      "Epoch 17/25\n",
      "32/32 [==============================] - 1339s 42s/step - loss: 0.6177 - acc: 0.7625\n",
      "Epoch 18/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.6142 - acc: 0.7375\n",
      "Epoch 19/25\n",
      "32/32 [==============================] - 1344s 42s/step - loss: 0.5326 - acc: 0.7625\n",
      "Epoch 20/25\n",
      "32/32 [==============================] - 1333s 42s/step - loss: 0.5961 - acc: 0.7500\n",
      "Epoch 21/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.5890 - acc: 0.7719\n",
      "Epoch 22/25\n",
      "32/32 [==============================] - 1348s 42s/step - loss: 0.5357 - acc: 0.7906\n",
      "Epoch 23/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.5692 - acc: 0.7812\n",
      "Epoch 24/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 0.5211 - acc: 0.7906\n",
      "Epoch 25/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.5450 - acc: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f696430a150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opt = tf.keras.optimizers.Adam()\n",
    "# model.compile(\n",
    "#     optimizer=opt,\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['acc'])\n",
    "# model.fit(\n",
    "#     train_data,\n",
    "#     epochs=25,\n",
    "#     verbose=1,\n",
    "#     class_weight=class_weights\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "32/32 [==============================] - 1362s 43s/step - loss: 4.3392 - acc: 0.6625\n",
      "Epoch 2/25\n",
      "32/32 [==============================] - 1345s 42s/step - loss: 2.0393 - acc: 0.6812\n",
      "Epoch 3/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 1.4665 - acc: 0.7000\n",
      "Epoch 4/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 1.2291 - acc: 0.6812\n",
      "Epoch 5/25\n",
      "32/32 [==============================] - 1348s 42s/step - loss: 1.0241 - acc: 0.6719\n",
      "Epoch 6/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.7949 - acc: 0.7094\n",
      "Epoch 7/25\n",
      "32/32 [==============================] - 1358s 42s/step - loss: 0.7622 - acc: 0.7094\n",
      "Epoch 8/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.6581 - acc: 0.7500\n",
      "Epoch 9/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.7004 - acc: 0.7406\n",
      "Epoch 10/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 0.6383 - acc: 0.7312\n",
      "Epoch 11/25\n",
      "32/32 [==============================] - 1353s 42s/step - loss: 0.6408 - acc: 0.7344\n",
      "Epoch 12/25\n",
      "32/32 [==============================] - 1336s 42s/step - loss: 0.6847 - acc: 0.7344\n",
      "Epoch 13/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.6471 - acc: 0.7219\n",
      "Epoch 14/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.6270 - acc: 0.7469\n",
      "Epoch 15/25\n",
      "32/32 [==============================] - 1333s 42s/step - loss: 0.6136 - acc: 0.7625\n",
      "Epoch 16/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.5680 - acc: 0.7781\n",
      "Epoch 17/25\n",
      "32/32 [==============================] - 1339s 42s/step - loss: 0.6177 - acc: 0.7625\n",
      "Epoch 18/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.6142 - acc: 0.7375\n",
      "Epoch 19/25\n",
      "32/32 [==============================] - 1344s 42s/step - loss: 0.5326 - acc: 0.7625\n",
      "Epoch 20/25\n",
      "32/32 [==============================] - 1333s 42s/step - loss: 0.5961 - acc: 0.7500\n",
      "Epoch 21/25\n",
      "32/32 [==============================] - 1335s 42s/step - loss: 0.5890 - acc: 0.7719\n",
      "Epoch 22/25\n",
      "32/32 [==============================] - 1348s 42s/step - loss: 0.5357 - acc: 0.7906\n",
      "Epoch 23/25\n",
      "32/32 [==============================] - 1340s 42s/step - loss: 0.5692 - acc: 0.7812\n",
      "Epoch 24/25\n",
      "32/32 [==============================] - 1338s 42s/step - loss: 0.5211 - acc: 0.7906\n",
      "Epoch 25/25\n",
      "32/32 [==============================] - 1341s 42s/step - loss: 0.5450 - acc: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f696430a150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc'])\n",
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=25,\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 341s 43s/step - loss: 2.1043 - acc: 0.5125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.104286551475525, 0.5125]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    test_data,\n",
    "    #     class_weight=class_weights\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200126_130923'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempted to save a function b'__inference_conv_lst_m2d_layer_call_fn_83850' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 128, 128, 3), dtype=float32) that is not a simple constant. This is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ddd22cc40ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msavepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/data/models/{dt}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 115\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m# default learning phase placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    891\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[0;32m--> 893\u001b[0;31m       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\n\u001b[0m\u001b[1;32m    894\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m    895\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0mresource_initializer_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mexported_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m     \u001b[0mobject_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresource_initializer_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresource_initializer_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0masset_dependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/deepfake/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36mmap_resources\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 (\"Attempted to save a function {} which references a symbolic \"\n\u001b[1;32m    291\u001b[0m                  \u001b[0;34m\"Tensor {} that is not a simple constant. This is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                  \"supported.\").format(concrete_function.name, capture))\n\u001b[0m\u001b[1;32m    293\u001b[0m           \u001b[0mcopied_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapture_constant_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m           \u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempted to save a function b'__inference_conv_lst_m2d_layer_call_fn_83850' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 128, 128, 3), dtype=float32) that is not a simple constant. This is not supported."
     ]
    }
   ],
   "source": [
    "savepath = f'/data/models/{dt}'\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "model.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
